{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Camera Anomaly Detection V2 - Training Notebook\n",
    "\n",
    "This notebook is designed to run on Google Colab (A100 GPU) or locally.\n",
    "It uses Multiple Instance Learning (MIL) with a ResNet50V2 backbone."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Setup Environment\n",
    "import sys\n",
    "import os\n",
    "\n",
    "if 'google.colab' in sys.modules:\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive')\n",
    "    \n",
    "    # UPDATE THIS PATH TO MATCH YOUR DRIVE LOCATION\n",
    "    PROJECT_PATH = '/content/drive/MyDrive/Colab Notebooks/camera_anomaly_detection_v2'\n",
    "    \n",
    "    if not os.path.exists(PROJECT_PATH):\n",
    "        print(f\"WARNING: Project path {PROJECT_PATH} not found. Please check your Drive structure.\")\n",
    "    else:\n",
    "        os.chdir(PROJECT_PATH)\n",
    "        print(f\"Changed directory to {PROJECT_PATH}\")\n",
    "        \n",
    "    # Install dependencies\n",
    "    !python setup_env.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ef15801",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Verify Config and GPU\n",
    "from config import config\n",
    "from pathlib import Path\n",
    "\n",
    "# Standard Configuration for Cloud/AWS\n",
    "# config.DATA_DIR = Path('data/DCSASS Dataset') # Default\n",
    "# LOCAL QUICK RUN CONFIG\n",
    "config.EPOCHS = 1\n",
    "config.BATCH_SIZE = 1\n",
    "config.MAX_LABELS = None\n",
    "\n",
    "# Monkey-patch loader to only load Normal and Abuse\n",
    "import dcsass_loader\n",
    "original_load_metadata = dcsass_loader._load_metadata\n",
    "\n",
    "def restricted_load_metadata(root, seed=1337):\n",
    "    entries = original_load_metadata(root, seed)\n",
    "    # Filter for only Normal and Abuse\n",
    "    target_labels = {'Normal', 'Abuse'}\n",
    "    filtered_entries = [e for e in entries if e['label'] in target_labels]\n",
    "    \n",
    "    print(f\"Filtered dataset to {len(filtered_entries)} samples from classes: {target_labels}\")\n",
    "    return filtered_entries\n",
    "\n",
    "dcsass_loader._load_metadata = restricted_load_metadata\n",
    "\n",
    "config.display()\n",
    "\n",
    "import tensorflow as tf\n",
    "print(f\"TensorFlow Version: {tf.__version__}\")\n",
    "print(f\"GPU Available: {tf.config.list_physical_devices('GPU')}\")\n",
    "\n",
    "# Enable Mixed Precision for T4/A100 speedup and memory savings\n",
    "from tensorflow.keras import mixed_precision\n",
    "policy = mixed_precision.Policy('mixed_float16')\n",
    "mixed_precision.set_global_policy(policy)\n",
    "print(f\"Mixed precision policy set to: {policy.name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Load Data\n",
    "from dcsass_loader import make_bag_dataset\n",
    "\n",
    "print(\"Creating datasets...\")\n",
    "# Note: batch_size=1 means 1 bag per batch. Each bag contains T clips.\n",
    "train_ds = make_bag_dataset(\n",
    "    root=None, \n",
    "    split=\"train\", \n",
    "    batch_size=1, \n",
    "    cache_decoded=True\n",
    ")\n",
    "val_ds = make_bag_dataset(\n",
    "    root=None, \n",
    "    split=\"val\", \n",
    "    batch_size=1, \n",
    "    cache_decoded=True\n",
    ")\n",
    "\n",
    "print(\"Datasets created.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Build Model\n",
    "from model import build_mil_model\n",
    "\n",
    "model = build_mil_model()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. Training Loop\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=config.LEARNING_RATE)\n",
    "bce_loss = tf.keras.losses.BinaryCrossentropy()\n",
    "from tqdm import tqdm\n",
    "\n",
    "@tf.function\n",
    "def train_step(bag, label):\n",
    "    # bag: (1, T, H, W, C) - RaggedTensor or Tensor\n",
    "    # label: (1,)\n",
    "    \n",
    "    instances = bag[0] # (Num_Segments, T, H, W, C)\n",
    "    \n",
    "    # Flatten segments and time: (Num_Segments * T, H, W, C)\n",
    "    # ResNet50 expects 4D input (Batch, H, W, C)\n",
    "    flat_instances = tf.reshape(instances, (-1, 224, 224, 3))\n",
    "    \n",
    "    with tf.GradientTape() as tape:\n",
    "        scores = model(flat_instances, training=True)\n",
    "        max_score = tf.reduce_max(scores)\n",
    "        \n",
    "        # Ensure shapes are (1,) for BCE\n",
    "        max_score = tf.expand_dims(max_score, 0)\n",
    "        loss = bce_loss(label, max_score)\n",
    "        \n",
    "    gradients = tape.gradient(loss, model.trainable_variables)\n",
    "    optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
    "    \n",
    "    return loss, max_score\n",
    "\n",
    "print(\"Starting training...\")\n",
    "for epoch in range(config.EPOCHS):\n",
    "    print(f\"\\nEpoch {epoch+1}/{config.EPOCHS}\")\n",
    "    \n",
    "    # Training\n",
    "    total_loss = 0.0\n",
    "    steps = 0\n",
    "    for bag, label, vid_id in tqdm(train_ds, desc=\"Training\"):\n",
    "        # bag is RaggedTensor, convert to tensor if needed, but bag[0] should work if it's uniform T\n",
    "        # If T varies, bag[0] is a tensor of shape (T_actual, H, W, C)\n",
    "        if isinstance(bag, tf.RaggedTensor):\n",
    "            bag = bag.to_tensor()\n",
    "            \n",
    "        loss, score = train_step(bag, label)\n",
    "        total_loss += loss\n",
    "        steps += 1\n",
    "        \n",
    "    avg_loss = total_loss / steps\n",
    "    print(f\"Train Loss: {avg_loss:.4f}\")\n",
    "    \n",
    "    # Validation\n",
    "    val_loss = 0.0\n",
    "    val_steps = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    for bag, label, vid_id in tqdm(val_ds, desc=\"Validation\"):\n",
    "        if isinstance(bag, tf.RaggedTensor):\n",
    "            bag = bag.to_tensor()\n",
    "            \n",
    "        instances = bag[0]\n",
    "        \n",
    "        # Flatten segments and time for validation as well\n",
    "        flat_instances = tf.reshape(instances, (-1, 224, 224, 3))\n",
    "        \n",
    "        scores = model(flat_instances, training=False)\n",
    "        max_score = tf.reduce_max(scores)\n",
    "        \n",
    "        # Ensure shapes for BCE\n",
    "        max_score = tf.expand_dims(max_score, 0)\n",
    "        loss = bce_loss(label, max_score)\n",
    "        \n",
    "        val_loss += loss\n",
    "        val_steps += 1\n",
    "        \n",
    "        # Accuracy\n",
    "        pred = 1 if max_score > 0.5 else 0\n",
    "        if pred == label[0]:\n",
    "            correct += 1\n",
    "        total += 1\n",
    "        \n",
    "    if val_steps > 0:\n",
    "        print(f\"Val Loss: {val_loss/val_steps:.4f}, Val Acc: {correct/total:.4f}\")\n",
    "    else:\n",
    "        print(\"Val Loss: N/A, Val Acc: N/A (No validation samples)\")\n",
    "    \n",
    "    # Save Checkpoint\n",
    "    if (epoch + 1) % 5 == 0:\n",
    "        ckpt_path = config.CHECKPOINT_DIR / f\"model_epoch_{epoch+1}.h5\"\n",
    "        config.CHECKPOINT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "        model.save_weights(str(ckpt_path))\n",
    "        print(f\"Saved checkpoint to {ckpt_path}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
